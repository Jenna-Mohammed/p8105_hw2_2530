p8105_hw2_2530
================
Jenna Mohammed
2023-10-04

``` r
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
library(tidyr)
library(tidyverse)
```

    ## -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
    ## v forcats   1.0.0     v readr     2.1.4
    ## v ggplot2   3.4.3     v stringr   1.5.0
    ## v lubridate 1.9.2     v tibble    3.2.1
    ## v purrr     1.0.1

    ## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()
    ## i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem \#1

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"),sep = "-") %>%
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
    #year, month, everything(), -day, -starts_with("prez")) |> 
  #left_join(x = _, y = month_df)

snp = 
  read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

    ## Rows: 787 Columns: 2
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment = 
  read_csv("./fivethirtyeight_datasets/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) 
```

    ## Rows: 68 Columns: 13
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Problem \#2

Read in each sheet from the trash wheel dataset. Clean each sheet by
using the janitor function and removing unnecessary rows. Use the mutate
function to create a new variable to determine the amount of homes that
are powered by the trash found in each trash wheel.

``` r
# Mr Trash Wheel

mtw_sheet = read_excel("./trashwheel_data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
    mutate(
      homes_powered = (weight_tons * 500)/30
    )
```

    ## New names:
    ## * `` -> `...15`
    ## * `` -> `...16`

``` r
# Professor Trash Wheel
ptw_sheet = read_excel("./trashwheel_data.xlsx",
  sheet = "Professor Trash Wheel", 
  skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
    mutate(
      homes_powered = (weight_tons * 500)/30
    )
                       
print(ptw_sheet)
```

    ## # A tibble: 106 x 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # i 96 more rows
    ## # i 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
# Captain Trash Wheel

ctw_sheet = read_excel("./trashwheel_data.xlsx",
  sheet = "Captain Trash Wheel",
  skip = 1) |>
  janitor::clean_names()|>
  drop_na(dumpster) |>
    mutate(
      homes_powered = (weight_tons * 500)/30
    )

print(ctw_sheet)
```

    ## # A tibble: 28 x 12
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 June      2018 2018-06-30 00:00:00        0.96                 10
    ##  2        2 July      2018 2018-07-19 00:00:00        1.47                 10
    ##  3        3 July      2018 2018-07-23 00:00:00        3.19                 10
    ##  4        4 August    2018 2018-08-08 00:00:00        1.11                 10
    ##  5        5 October   2018 2018-10-15 00:00:00        1.44                 10
    ##  6        6 December  2018 2018-12-14 00:00:00        0.66                  8
    ##  7        7 March     2019 2019-03-07 00:00:00        0.98                  8
    ##  8        8 April     2019 2019-04-24 00:00:00        1.8                  10
    ##  9        9 May       2019 2019-05-31 00:00:00        2.17                 10
    ## 10       10 August    2019 2019-08-08 00:00:00        1.21                  9
    ## # i 18 more rows
    ## # i 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

``` r
# Gwynnda Trash Wheel

gtw_sheet = read_excel("./trashwheel_data.xlsx",
  sheet = "Gwynnda Trash Wheel", 
  skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
    mutate(
      homes_powered = (weight_tons * 500)/30
    )

print(gtw_sheet)
```

    ## # A tibble: 155 x 12
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # i 145 more rows
    ## # i 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

Combining the three datasets

``` r
total_tw_data = 
  bind_rows(ptw_sheet, gtw_sheet, ctw_sheet)

print(total_tw_data) 
```

    ## # A tibble: 289 x 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # i 279 more rows
    ## # i 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

Description: After combining the three datasets, there are 289
observations and 13 variables. Some Key variables are the weight and
volume collected, homes powered, and the different types of trash
collected. Professor Trash Wheel collected 216.126 tons of of trash. In
July 2021, Gwynnda collected 16300 cigarette butts.

The `Mr. Trash Wheel Sheet` has 584 observations and 16 columns

The `Professor Trash Wheel` Sheet has 106 observations and 13 columns

The `Gwynnda Trash Wheel` Sheet has 155 observations and 12 columns

The Combined trash wheel data has 289 observations and 13 columns

## Problem 3

Loading in MCI Baseline data and cleaning by removing ineligible
participants. Using the mutate function to change the numerical values
to categorical ones.

``` r
# Changing sex and APOE4 carrier status from numerical to categorical

mci_baseline_df = read_csv("./data_mci./data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names()|>
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    sex = as.factor(sex)) |>
  mutate(
    apoe4 = 
      case_match(
        apoe4, 
        1 ~ "carrier", 
        0 ~ "non-carier"),
    apoe4 = as.factor(apoe4)) |>
    
# remove any participants who do not meet the stated inclusion criteria 

filter(age_at_onset == "."| age_at_onset > current_age)
```

    ## Rows: 483 Columns: 6
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

Finding the mean baseline age

``` r
mean(mci_baseline_df$current_age)
```

    ## [1] 65.0286

Determining the proportion of women in the study that are APOE4 carriers

``` r
data_female = filter(mci_baseline_df, sex == "female")
nrow(data_female)
```

    ## [1] 210

``` r
data_female_carrier = filter(data_female, apoe4 == "carrier")
nrow(data_female_carrier)
```

    ## [1] 63

MCI Baseline description: There are 479 participants in this dataset,
and from that \_\_\_\_ developed MCI. The average baseline age is 65.03.
The proportion of women in the study that are APOE4 carriers is 63/479.

Loading in and cleaning MCI Longtitudinal data by using the janitor
function.

``` r
mci_amyloid_df = read_csv("./data_mci./data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names()|>
  mutate()
```

    ## Rows: 487 Columns: 6
    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

Combining demographic and biomarker datasets

``` r
colnames(mci_amyloid_df)[colnames(mci_amyloid_df) == "study_id"] = "id"

mci_combined_df = full_join(mci_baseline_df, mci_amyloid_df, by = c("id"))

view(mci_combined_df)
```

To ask TA:

- how to get rid of warnings when knitting

Problem 3 - how to find how many people developed MCI - nrow,
\_antijoin - export result to CSV
